{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-21T18:35:12.543910Z",
     "start_time": "2024-05-21T18:35:09.856066Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, when, isnan, count, udf, round as spark_round\n",
    "from pyspark.sql.types import StringType, FloatType\n",
    "\n",
    "\n",
    "from src.utils.s3_manager import S3Manager\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import os \n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data_dir = \"/Users/ilan/big-data-airflow-project/data\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T18:35:12.558429Z",
     "start_time": "2024-05-21T18:35:12.546961Z"
    }
   },
   "id": "3026c544229bc24"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/21 20:35:17 WARN Utils: Your hostname, Ordinateur-portable-de-Ilan.local resolves to a loopback address: 127.0.0.1; using 192.168.1.18 instead (on interface en0)\n",
      "24/05/21 20:35:17 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/21 20:35:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"EDA with Spark\") \\\n",
    "    .getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T18:35:23.584397Z",
     "start_time": "2024-05-21T18:35:12.560678Z"
    }
   },
   "id": "8ba8718f5623d0f6"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "df = spark.read.parquet(data_dir+\"/allocine_movies.parquet\", header=True, inferSchema=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T11:30:43.762952Z",
     "start_time": "2024-05-20T11:30:43.626361Z"
    }
   },
   "id": "907777847cac46be"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Runtime: string (nullable = true)\n",
      " |-- Genre: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- Actors: string (nullable = true)\n",
      " |-- Summary: string (nullable = true)\n",
      " |-- Rating: double (nullable = true)\n",
      " |-- Action: integer (nullable = true)\n",
      " |-- Adventure: integer (nullable = true)\n",
      " |-- Animation: integer (nullable = true)\n",
      " |-- Biopic: integer (nullable = true)\n",
      " |-- Comedy: integer (nullable = true)\n",
      " |-- Crime: integer (nullable = true)\n",
      " |-- Documentary: integer (nullable = true)\n",
      " |-- Drama: integer (nullable = true)\n",
      " |-- Horror: integer (nullable = true)\n",
      " |-- Famille: integer (nullable = true)\n",
      " |-- Guerre: integer (nullable = true)\n",
      " |-- MusicalRomance: integer (nullable = true)\n",
      " |-- Sci-Fi: integer (nullable = true)\n",
      " |-- Thriller: integer (nullable = true)\n",
      " |-- Western: integer (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T11:30:44.729705Z",
     "start_time": "2024-05-20T11:30:44.726318Z"
    }
   },
   "id": "b437f5d395b49338"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:55.027688Z"
    }
   },
   "id": "fb85b0e29186c4e1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"The shape of the allocine dataset is \", (df.count(), len(df.columns)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:55.032628Z"
    }
   },
   "id": "d58f5b54febd4655"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.drop(\"Release Date\", \"Director\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:55.035781Z"
    }
   },
   "id": "55b7bfd30b2b0206"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Renaming columns to match the netflix dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a95feb29ab110336"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"Duration\", \"Runtime\")\n",
    "df = df.withColumnRenamed(\"Synopsis\", \"Summary\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:55.038227Z"
    }
   },
   "id": "438622126166538c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dealing with missing values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3457d757a51107c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "missing_values = df.select([count(when(col(c).isNull() | isnan(c), c)).alias(c) for c in df.columns])\n",
    "missing_values.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:55.043468Z"
    }
   },
   "id": "6d681e6ad9e4335b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Runtime column"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcbcc695991f4728"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"Runtime\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:55.048083Z"
    }
   },
   "id": "73bec8832f462ba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def convert_runtime_to_interval(runtime):\n",
    "    hours, minutes = map(int, runtime.replace('min', '').replace('h', '').split())\n",
    "    total_hours = hours + minutes / 60\n",
    "    if total_hours > 2:\n",
    "        return '> 2 hrs'\n",
    "    elif total_hours < 0.5:\n",
    "        return '< 30 minutes'\n",
    "    elif total_hours < 1 and total_hours >= 0.5 :\n",
    "        return '30 - 60 mins'\n",
    "    else:\n",
    "        return '1-2 hour'\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T11:26:55.101739Z",
     "start_time": "2024-05-20T11:26:55.055076Z"
    }
   },
   "id": "7db8c00db5187eb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "convert_runtime_udf = udf(convert_runtime_to_interval, StringType())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:55.063788Z"
    }
   },
   "id": "a9252085a934b312"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Runtime\", convert_runtime_udf(df[\"Runtime\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:55.066264Z"
    }
   },
   "id": "cf655b16ffa5bec0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:55.069096Z"
    }
   },
   "id": "b37da913dc2ab667"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Rating column\n",
    "\n",
    "We're gonna merge the spectator rating and the press rating into one column called rating"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f1ac5415a5d4aa4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "df = df.withColumn(\"Press Rating\", regexp_replace(col(\"Press Rating\"), \",\", \".\"))\n",
    "df = df.withColumn(\"Press Rating\", when(col(\"Press Rating\") == \"--\", None).otherwise(col(\"Press Rating\")))\n",
    "df = df.withColumn(\"Press Rating\", col(\"Press Rating\").cast(FloatType()))\n",
    "\n",
    "df = df.withColumn(\"Spectator Rating\", regexp_replace(col(\"Spectator Rating\"), \",\", \".\"))\n",
    "df = df.withColumn(\"Spectator Rating\", when(col(\"Spectator Rating\") == \"--\", None).otherwise(col(\"Spectator Rating\")))\n",
    "df = df.withColumn(\"Spectator Rating\", col(\"Spectator Rating\").cast(FloatType()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:55.071315Z"
    }
   },
   "id": "b27a9c8c98f77f9c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "\n",
    "mean_press = df.select(mean(col(\"Press Rating\")).alias(\"mean_press\")).collect()[0][\"mean_press\"]\n",
    "df = df.na.fill({\"Press Rating\": mean_press})\n",
    "\n",
    "mean_spectator = df.select(mean(col(\"Spectator Rating\")).alias(\"mean_spectator\")).collect()[0][\"mean_spectator\"]\n",
    "df = df.na.fill({\"Spectator Rating\": mean_spectator})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:55.077868Z"
    }
   },
   "id": "2380786ebb5e6d01"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Rating\", spark_round((col(\"Press Rating\") + col(\"Spectator Rating\")) / 2, 1))\n",
    "df = df.drop(\"Press Rating\", \"Spectator Rating\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:55.081227Z"
    }
   },
   "id": "3bb37ff74b42c2de"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:55.083501Z"
    }
   },
   "id": "30f01a6225f14d03"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Transform the genre column. We will create one col for each genre and fill it with 1 if the movie belongs to this genre, 0 otherwise"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f91201c165a1e58"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split\n",
    "\n",
    "df = df.withColumn(\"Genre\", split(col(\"Genre\"), \", \"))\n",
    "genres = [\"Action\", \"Adventure\", \"Drama\", \"Sci-Fi\", \"Crime\", \"Thriller\", \"Comedy\", \"Biography\", \"Documentary\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:55.085572Z"
    }
   },
   "id": "eaa40c274d2f20d2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array_contains\n",
    "\n",
    "for genre in genres:\n",
    "    df = df.withColumn(genre, array_contains(col(\"Genre\"), genre).cast(\"integer\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:55.087368Z"
    }
   },
   "id": "c7737e423bee024"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:55.088942Z"
    }
   },
   "id": "1192aabb556f4563"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.groupBy(\"Genre\").count().orderBy(col(\"count\").desc()).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:55.091546Z"
    }
   },
   "id": "1f4d8d4885b04c67"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mdf\u001B[49m\u001B[38;5;241m.\u001B[39mprintSchema())\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(df.printSchema())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T11:27:07.066619Z",
     "start_time": "2024-05-20T11:27:07.048759Z"
    }
   },
   "id": "2e41ecf4d28d8001"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
